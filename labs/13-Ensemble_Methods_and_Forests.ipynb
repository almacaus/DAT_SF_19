{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT19 Lab 13\n",
    "## Ensemble Methods: Aggregating Models\n",
    "\n",
    "\n",
    "Today's lab covers:\n",
    "1. Investigating the Decision Boundaries\n",
    "2. Growing a Random Forest\n",
    "\n",
    "The theory used to introduce these concepts can be a bit high level. We postulate a theoretical *true* classification **f** function that perfectly labels a data point given a large enough set of input features. We try to come as close as possible to this **f** with our learned classifier **h**. \n",
    "\n",
    "The concept of our *hypothesis space* is what we explore when we take our data, learn a model, and determine the \"score\" of our model. In theory, a cross validated score of 100 is as close as we can get to **f** and all these improvements we make to our classifiers are moving through the hypothesis space, approaching **f**.\n",
    "\n",
    "This theoretical component has no true lab but in a sense is every lab that we've covered. Whenever we compare the performance of two separate models, we are comparing the difference from two distinct starting points in the hypothesis space.\n",
    "\n",
    "A way to demonstrate this will be the basis of the first part of our lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named discriminant_analysis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-61acdafa4e6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminant_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearDiscriminantAnalysis\u001b[0m  \u001b[1;32mas\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminant_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuadraticDiscriminantAnalysis\u001b[0m  \u001b[1;32mas\u001b[0m \u001b[0mQDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named discriminant_analysis"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis  as QDA\n",
    "\n",
    "from bokeh.plotting import figure,gridplot,show,output_notebook\n",
    "from bokeh.models import Range1d\n",
    "output_notebook()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Investigating Decision Boundaries\n",
    "Visually understanding how some classifiers make decisions; adapted from an sklearn page, which will be shared after lab. \n",
    "\n",
    "The goal here is to investigate the code and describe in layman's terms what is happening in the specific chunk. If there is a variable being referenced outside of your chunk, or your in a loop, refer to what's happening in one iteration of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LDA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d62a7ecf4be1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     QDA()]\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LDA' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================================== #\n",
    "# Part 1\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"AdaBoost\", \"Naive Bayes\", \"LDA\", \"QDA\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LDA(),\n",
    "    QDA()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe here what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c9229abd4514>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfull_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# NOTE THIS IS A FOR LOOP, so decribe what happens on one iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# ====================================================================== #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "full_grid = []\n",
    "for data in datasets:\n",
    "    \n",
    "# NOTE THIS IS A FOR LOOP, so decribe what happens on one iteration\n",
    "# ====================================================================== #\n",
    "# Part 2\n",
    "\n",
    "    h = .02  # step size in the meshgrid\n",
    "    \n",
    "    X, y = data\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "# ====================================================================== #\n",
    "    # Part 3\n",
    "    raw = figure(title=\"Raw Data\", tools='',\n",
    "                x_range=(xx.min(), xx.max()), \n",
    "                y_range=(yy.min(), yy.max()),\n",
    "                width=180, plot_height=220,\n",
    "                min_border=1,\n",
    "                title_text_font_size='10pt' )\n",
    "\n",
    "    color_dict = {0:'blue',1:'red'}\n",
    "\n",
    "    train_colors = [color_dict[label] for label in y_train]\n",
    "    raw.circle(X_train[:, 0], X_train[:, 1], \n",
    "               color=train_colors)\n",
    "\n",
    "    test_colors = [color_dict[label] for label in y_test]\n",
    "    raw.circle(X_test[:, 0], X_test[:, 1], \n",
    "               color=test_colors, alpha=0.6)\n",
    "\n",
    "\n",
    "    \n",
    "# ====================================================================== #\n",
    "# Part 4\n",
    "\n",
    "    row=[raw]\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        \n",
    "        Z = Z.reshape(xx.shape)\n",
    "        Z = Z/Z.max()\n",
    "        control_row = np.ones(Z.shape[1])+0.001\n",
    "        #NOTE: control row adds a max value outside of the grid to correct colors. \n",
    "        # Don't worry about explaining control_row\n",
    "        Z = np.vstack((Z,control_row))\n",
    "\n",
    "\n",
    "# ====================================================================== #\n",
    "# Part 5\n",
    "        p1 = figure(title=name, tools='',\n",
    "                    x_range=(xx.min(), xx.max()), \n",
    "                    y_range=(yy.min(), yy.max()),\n",
    "                    width=180, plot_height=220,\n",
    "                    min_border=1,\n",
    "                    title_text_font_size='10pt')\n",
    "\n",
    "\n",
    "        p1.image(image=[Z], x=[xx.min()], y=[yy.min()], dw=[xx.max()-xx.min()], dh=[yy.max()-yy.min()],\n",
    "                palette='RdYlBu11')\n",
    "\n",
    "        p1.circle(X_train[:, 0], X_train[:, 1], \n",
    "                  color=train_colors,\n",
    "                  line_color='black',\n",
    "                  size=3)\n",
    "        p1.circle(X_test[:, 0], X_test[:, 1], \n",
    "                  color=test_colors, \n",
    "                  alpha=0.6,\n",
    "                  line_color='black',\n",
    "                  size=3)\n",
    "\n",
    "        p1.text(x=[xx.max()-1.5],y=[yy.min()],\n",
    "                text=[str(score)],\n",
    "                text_font_size='15pt',\n",
    "                text_font_style='bold')\n",
    "        \n",
    "        row.append(p1)\n",
    "    \n",
    "    grid = np.array(row).reshape(2,len(row)/2)\n",
    "    full_grid.append(grid)\n",
    "    \n",
    "final_grid = np.vstack(full_grid)\n",
    "show(gridplot(final_grid.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "Random forests are a type of ensemble method (which we hinted at above) that build out groups of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess our data. Age needs to be imputed or dropped, Sex needs to be converted to a boolean data type, and to use our categorical feature `Embarked` we must use `pd.get_dummies` on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_age = titanic['Age'].mean()\n",
    "titanic['Age'] = titanic['Age'].fillna(average_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>is_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked is_female  \n",
       "0      0         A/5 21171   7.2500   NaN        S     False  \n",
       "1      0          PC 17599  71.2833   C85        C      True  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S      True  \n",
       "3      0            113803  53.1000  C123        S      True  \n",
       "4      0            373450   8.0500   NaN        S     False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['is_female'] = titanic.Sex=='female'\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>is_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked is_female  Embarked_C  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S     False           0   \n",
       "1      0          PC 17599  71.2833   C85        C      True           1   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S      True           0   \n",
       "3      0            113803  53.1000  C123        S      True           0   \n",
       "4      0            373450   8.0500   NaN        S     False           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embarked_categories = pd.get_dummies(titanic.Embarked,prefix='Embarked')\n",
    "titanic[embarked_categories.columns] = embarked_categories\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns = 'Age,Parch,Pclass,Fare,Embarked_C,Embarked_Q,Embarked_S'.split(',')\n",
    "for train,test in ShuffleSplit(len(titanic),test_size=.2,n_iter = 1):\n",
    "\n",
    "    X_train = titanic[feature_columns].iloc[train]\n",
    "    y_train = titanic['Survived'].iloc[train]\n",
    "    X_test = titanic[feature_columns].iloc[test]\n",
    "    y_test = titanic['Survived'].iloc[test]\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68715083798882681"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We already imported the RandomForest above, but here it is for reference:\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=5, n_estimators=100, max_features=3)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting general score but let's be more thorough and get a cross evaluation score, and see how it grows with the size of our forest (`n_estimators`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'figure' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fe97dc2b2003>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Random Forest Classifier performance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforest_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'figure' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "features = titanic[feature_columns]\n",
    "target = titanic['Survived']\n",
    "\n",
    "forest_size = range(2,100,2)\n",
    "y = []\n",
    "for i in forest_size:\n",
    "    rfc = RandomForestClassifier(max_depth=5, n_estimators=i, max_features=4)\n",
    "    accuracy = cross_val_score(rfc, features, target, cv=5).mean()\n",
    "    \n",
    "    y.append(accuracy)\n",
    "p1 = figure(title='Random Forest Classifier performance',tools='')\n",
    "p1.line(x=forest_size,y=y, color='green')\n",
    "\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the classifier change as we allow for more complexity?  (i.e. deeper trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_depth = range(1,50)\n",
    "y = []\n",
    "for i in tree_depth:\n",
    "    rfc = RandomForestClassifier(max_depth=i, n_estimators=20, max_features=4)\n",
    "    accuracy = cross_val_score(rfc, features, target, cv=5).mean()\n",
    "    \n",
    "    y.append(accuracy)\n",
    "p1 = figure(title='Random Forest Classifier performance',x_axis_label='Max Tree Depth',tools='')\n",
    "p1.line(x=tree_depth,y=y, color='green')\n",
    "\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise: Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>intl_plan</th>\n",
       "      <th>vmail_plan</th>\n",
       "      <th>vmail_message</th>\n",
       "      <th>day_mins</th>\n",
       "      <th>day_calls</th>\n",
       "      <th>day_charge</th>\n",
       "      <th>eve_mins</th>\n",
       "      <th>eve_calls</th>\n",
       "      <th>eve_charge</th>\n",
       "      <th>night_mins</th>\n",
       "      <th>night_calls</th>\n",
       "      <th>night_charge</th>\n",
       "      <th>intl_mins</th>\n",
       "      <th>intl_calls</th>\n",
       "      <th>intl_charge</th>\n",
       "      <th>custserv_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length  area_code intl_plan vmail_plan  vmail_message  \\\n",
       "0    KS             128        415        no        yes             25   \n",
       "1    OH             107        415        no        yes             26   \n",
       "2    NJ             137        415        no         no              0   \n",
       "3    OH              84        408       yes         no              0   \n",
       "4    OK              75        415       yes         no              0   \n",
       "\n",
       "   day_mins  day_calls  day_charge  eve_mins  eve_calls  eve_charge  \\\n",
       "0     265.1        110       45.07     197.4         99       16.78   \n",
       "1     161.6        123       27.47     195.5        103       16.62   \n",
       "2     243.4        114       41.38     121.2        110       10.30   \n",
       "3     299.4         71       50.90      61.9         88        5.26   \n",
       "4     166.7        113       28.34     148.3        122       12.61   \n",
       "\n",
       "   night_mins  night_calls  night_charge  intl_mins  intl_calls  intl_charge  \\\n",
       "0       244.7           91         11.01       10.0           3         2.70   \n",
       "1       254.4          103         11.45       13.7           3         3.70   \n",
       "2       162.6          104          7.32       12.2           5         3.29   \n",
       "3       196.9           89          8.86        6.6           7         1.78   \n",
       "4       186.9          121          8.41       10.1           3         2.73   \n",
       "\n",
       "   custserv_calls  churn  \n",
       "0               1  False  \n",
       "1               1  False  \n",
       "2               0  False  \n",
       "3               2  False  \n",
       "4               3  False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cell_phone_churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3333 entries, 0 to 3332\n",
      "Data columns (total 20 columns):\n",
      "state             3333 non-null object\n",
      "account_length    3333 non-null int64\n",
      "area_code         3333 non-null int64\n",
      "intl_plan         3333 non-null object\n",
      "vmail_plan        3333 non-null object\n",
      "vmail_message     3333 non-null int64\n",
      "day_mins          3333 non-null float64\n",
      "day_calls         3333 non-null int64\n",
      "day_charge        3333 non-null float64\n",
      "eve_mins          3333 non-null float64\n",
      "eve_calls         3333 non-null int64\n",
      "eve_charge        3333 non-null float64\n",
      "night_mins        3333 non-null float64\n",
      "night_calls       3333 non-null int64\n",
      "night_charge      3333 non-null float64\n",
      "intl_mins         3333 non-null float64\n",
      "intl_calls        3333 non-null int64\n",
      "intl_charge       3333 non-null float64\n",
      "custserv_calls    3333 non-null int64\n",
      "churn             3333 non-null bool\n",
      "dtypes: bool(1), float64(8), int64(8), object(3)\n",
      "memory usage: 524.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some Preprocessing\n",
    "state_encoder = LabelEncoder()  \n",
    "df.state = state_encoder.fit_transform(df.state)\n",
    "\n",
    "\n",
    "binary_columns = ['intl_plan', 'vmail_plan']  \n",
    "for col in binary_columns:  \n",
    "    df[col] = df[col].map({\n",
    "            'no': 0,\n",
    "            'yes': 1\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "----\n",
    "Explore the data and plot histograms of several columns. Hypothesize whether a relationship exists. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f8b6f60>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1faf2400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To get you started:\n",
    "df['churn'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-c4af04b72925>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-34-c4af04b72925>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    help df['churn']\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and compare the `precision and recall` of \n",
    "    - `GradientBoostingClassifier` \n",
    "    - `RandomForestClassifier`\n",
    "    - `DecisionTreeClassifier`\n",
    "    - `LogisticRegression`\n",
    "        - hint!: use the `precision_recall_fscore_support` built into sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function precision_recall_fscore_support in module sklearn.metrics.classification:\n",
      "\n",
      "precision_recall_fscore_support(y_true, y_pred, beta=1.0, labels=None, pos_label=1, average=None, warn_for=('precision', 'recall', 'f-score'), sample_weight=None)\n",
      "    Compute precision, recall, F-measure and support for each class\n",
      "    \n",
      "    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "    true positives and ``fp`` the number of false positives. The precision is\n",
      "    intuitively the ability of the classifier not to label as positive a sample\n",
      "    that is negative.\n",
      "    \n",
      "    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
      "    true positives and ``fn`` the number of false negatives. The recall is\n",
      "    intuitively the ability of the classifier to find all the positive samples.\n",
      "    \n",
      "    The F-beta score can be interpreted as a weighted harmonic mean of\n",
      "    the precision and recall, where an F-beta score reaches its best\n",
      "    value at 1 and worst score at 0.\n",
      "    \n",
      "    The F-beta score weights recall more than precision by a factor of\n",
      "    ``beta``. ``beta == 1.0`` means recall and precision are equally important.\n",
      "    \n",
      "    The support is the number of occurrences of each class in ``y_true``.\n",
      "    \n",
      "    If ``pos_label is None`` and in binary classification, this function\n",
      "    returns the average precision, recall and F-measure if ``average``\n",
      "    is one of ``'micro'``, ``'macro'``, ``'weighted'`` or ``'samples'``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    beta : float, 1.0 by default\n",
      "        The strength of recall versus precision in the F-score.\n",
      "    \n",
      "    labels : array\n",
      "        Integer array of labels.\n",
      "    \n",
      "    pos_label : str or int, 1 by default\n",
      "        The class to report if ``average='binary'``. Until version 0.18 it is\n",
      "        necessary to set ``pos_label=None`` if seeking to use another averaging\n",
      "        method over binary targets.\n",
      "    \n",
      "    average : string, [None (default), 'binary', 'micro', 'macro', 'samples',                        'weighted']\n",
      "        If ``None``, the scores for each class are returned. Otherwise, this\n",
      "        determines the type of averaging performed on the data:\n",
      "    \n",
      "        ``'binary'``:\n",
      "            Only report results for the class specified by ``pos_label``.\n",
      "            This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by counting the total true positives,\n",
      "            false negatives and false positives.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average, weighted\n",
      "            by support (the number of true instances for each label). This\n",
      "            alters 'macro' to account for label imbalance; it can result in an\n",
      "            F-score that is not between precision and recall.\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average (only\n",
      "            meaningful for multilabel classification where this differs from\n",
      "            :func:`accuracy_score`).\n",
      "    \n",
      "        Note that if ``pos_label`` is given in binary classification with\n",
      "        `average != 'binary'`, only that positive class is reported. This\n",
      "        behavior is deprecated and will change in version 0.18.\n",
      "    \n",
      "    warn_for : tuple or set, for internal use\n",
      "        This determines which warnings will be made in the case that this\n",
      "        function is being used to return only one of its metrics.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    precision: float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    \n",
      "    recall: float (if average is not None) or array of float, , shape =        [n_unique_labels]\n",
      "    \n",
      "    fbeta_score: float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    \n",
      "    support: int (if average is not None) or array of int, shape =        [n_unique_labels]\n",
      "        The number of occurrences of each label in ``y_true``.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Precision and recall\n",
      "           <http://en.wikipedia.org/wiki/Precision_and_recall>`_\n",
      "    \n",
      "    .. [2] `Wikipedia entry for the F1-score\n",
      "           <http://en.wikipedia.org/wiki/F1_score>`_\n",
      "    \n",
      "    .. [3] `Discriminative Methods for Multi-labeled Classification Advances\n",
      "           in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu\n",
      "           Godbole, Sunita Sarawagi\n",
      "           <http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf>`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import precision_recall_fscore_support\n",
      "    >>> y_true = np.array([0, 1, 2, 0, 1, 2])\n",
      "    >>> y_pred = np.array([0, 2, 1, 0, 0, 1])\n",
      "    >>> precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    (0.22..., 0.33..., 0.26..., None)\n",
      "    >>> precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    (0.33..., 0.33..., 0.33..., None)\n",
      "    >>> precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    (0.22..., 0.33..., 0.26..., None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "help(precision_recall_fscore_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the models using a grid-search of several parameters \n",
    "    - Determine which score (accuracy? F1 score? ...) you will use for your grid search. Explain why to your partner\n",
    "    - Hint: for `DecisionTreeClassifier` and `RandomForestClassifier`, \n",
    "        look at the docs to see which hyperparameters need tuning.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-6fe032064120>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-6fe032064120>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    help data churn\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "help data churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot feature importance for one of your models (using the `.feature_importances_` property)\n",
    "    - Hint: load `feature_importances_` into a `pandas.Series` and use `.plot(kind='barh')` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Plot a learning curve for the same model\n",
    "    - Hint: This one is tough! Remember that a learning curve is the cross_validation score of a model on the training and test sets as the model learns more and more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your Code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
